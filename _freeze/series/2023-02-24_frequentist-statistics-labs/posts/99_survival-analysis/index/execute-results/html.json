{
  "hash": "4fa79b42bc273f5bd41afd61572e167c",
  "result": {
    "markdown": "---\ntitle: Survival Analysis\ndescription: Time to events.\n\norder: 99\n---\n\n\n## Recommended Reading\n\n- [Applied Survival Analysis Using R](http://link.springer.com/10.1007/978-3-319-31245-3) by Dirk F. Moore\n- Chapters 9 to 15 in [Applied Longitudinal Data Analysis: Modeling Change and Event Occurrence](https://doi.org/10.1093/acprof:oso/9780195152968.001.0001) by Judith Singer and John Willett\n- [A package for survival analysis in R](https://cran.r-project.org/web/packages/survival/vignettes/survival.pdf) by Terry Therneau\n\n## Prerequisites\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(survival)\nlibrary(asaur)\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(ggdist)\n```\n:::\n\n\n## Overview\n\n> Survival analysis is the study of survival times and of the factors that influence them.\n\n### Censoring\n\nThere are X types of censoring:\n\n- Left censoring\n- Right censoring\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntribble(\n  ~id, ~time, ~event, ~censored,\n  \"p1\", 0, \"0\", FALSE,\n  \"p1\", 7, \"1\", TRUE,\n  \"p2\", 0, \"0\", FALSE,\n  \"p2\", 6, \"2\", FALSE\n) |>\n  ggplot(aes(x = time, y = id)) +\n    geom_line() +\n    geom_point(aes(shape = event, fill = censored), size = 5) +\n    scale_shape_manual(values = c(16, 21, 4)) +\n    scale_fill_manual(values = c(\"black\", \"white\")) +\n    guides(fill = \"none\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\nCensoring mechanisms can be classified into three types:\n\n- Type I: censoring times are pre-specified.\n- Type II: censoring occurs when a prespecified fraction of observations have failed.\n- Random: censoring occurs randomly.\n\n### Hazard and Survival functions\n\n> Survival analysis methods depend on the survival distribution, and two key ways of specifying it are the survival function and the hazard function.\n\n- Survival function: the probability of surviving up to a point $t$.\n- Hazard function: the instantaneous failure rate.\n\nSurvival distributions can also be represented with:\n\n- Cumulative risk function: the probability of surviving on or before a point $t$.\n- Cumulative hazard function: the area under the hazard function up to time $t$.\n\nSurvival functions are typically estimated with nonparametric methods:\n\n- Kaplan-Meier estimator\n- Nelson-Altschuler estimator\n\n## RCT: Veterans' Administration Lung Cancer study\n\nVeterans' Administration Lung Cancer study is a standard randomized clinical trial investigating the effect of a standard or test chemotherapy on time to death in 137 males with advanced inoperable lung cancer. The data for this trial comes from kalbfleischprentice_StatisticalAnalysisFailure_2002 and is included in the survival package as `veteran`. The following variables were recorded at intake:\n\n- `trt`:\tChemotherapy treatment type (1 = standard, 2 = test)\n- `celltype`: Histological tumour type (1 = squamous, 2 = smallcell, 3 = adeno, 4 = large)\n- `karno`: General medical status measured with the Karnofsky performance score (10-30 = completely hospitalized, 40-60 = partial confinement, 70-90 = able to care for self)\n- `diagtime`: Time in months from diagnosis to randomization\n- `age`: Age in years\n- `prior`: Prior therapy (0 = no, 10 = yes)\n\nSurvival was recorded as:\n\n- `time`: Survival time in days\n- `status`: Censoring status (0 = yes, 1 = no)\n\nWe can get a glimpse of the data with `dplyr::glimpse()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(veteran)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 137\n#> Columns: 8\n#> $ trt      <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n#> $ celltype <fct> squamous, squamous, squamous, squamous, squamous, squamous, s…\n#> $ time     <dbl> 72, 411, 228, 126, 118, 10, 82, 110, 314, 100, 42, 8, 144, 25…\n#> $ status   <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0…\n#> $ karno    <dbl> 60, 70, 60, 60, 70, 20, 40, 80, 50, 70, 60, 40, 30, 80, 70, 6…\n#> $ diagtime <dbl> 7, 5, 3, 9, 11, 5, 10, 29, 18, 6, 4, 58, 4, 9, 11, 3, 9, 2, 4…\n#> $ age      <dbl> 69, 64, 38, 63, 65, 49, 69, 68, 43, 70, 81, 63, 63, 52, 48, 6…\n#> $ prior    <dbl> 0, 10, 0, 10, 10, 0, 10, 0, 0, 0, 0, 10, 0, 10, 10, 0, 0, 0, …\n```\n:::\n:::\n\n\n### Exploratory data analysis\n\nRather than working with the raw data, we begin by estimating the survival function of the `veteran` data using the **Kaplan-Meier estimator**. We accomplish this with `survival::survfit()`, which estimates a survival curve for censored data using R's formula syntax. The response variable is a `Surv` object created with `survival::Surv()`, which tracks survival time and censoring; the predictor is `1`, which indicates this is an intercept-only model.\n\n::: {.column-margin}\nTo use alternative estimators for the survival function, specify the optional `stype` and `ctype` arguments in `survival::survfit()`. For the Nelson-Aalen estimator (aka Nelson-Altschuler or Fleming-Harrington) use `survfit(..., stype = 2, ctype = 1)`; for the \"fh2\" estimator use `survfit(..., stype = 2, ctype = 2)`. The default Kaplan-Meier estimator is equivalent to `survfit(..., stype = 1, ctype = 1)`.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_km_fit <- survfit(Surv(time, status) ~ 1, data = veteran)\n```\n:::\n\n\nAlthough we are interested in the survival function of the `veteran` data, the actual reason we began this way is because it provides a convenient method for transforming the raw data into a format better suited for some initial exploratory data analysis. We first add a time 0 to the `survfit` object with `survival::survfit0()` (otherwise the data will start at the first observation time) then get the transformed data with `broom::tidy()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_km_fit_tidy <- veterans_km_fit |>\n  survfit0() |>\n  tidy()\n\nglimpse(veterans_km_fit_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 102\n#> Columns: 8\n#> $ time      <dbl> 0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21,…\n#> $ n.risk    <dbl> 137, 137, 135, 134, 133, 132, 129, 125, 123, 122, 120, 118, …\n#> $ n.event   <dbl> 0, 2, 1, 1, 1, 3, 4, 2, 1, 2, 2, 2, 1, 3, 2, 2, 2, 1, 2, 3, …\n#> $ n.censor  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n#> $ estimate  <dbl> 1.0000000, 0.9854015, 0.9781022, 0.9708029, 0.9635036, 0.941…\n#> $ std.error <dbl> 0.00000000, 0.01039891, 0.01278345, 0.01481644, 0.01662791, …\n#> $ conf.high <dbl> 1.0000000, 1.0000000, 1.0000000, 0.9994081, 0.9954216, 0.981…\n#> $ conf.low  <dbl> 1.0000000, 0.9655208, 0.9539002, 0.9430165, 0.9326091, 0.903…\n```\n:::\n:::\n\n\nThis summary of the `veteran` data, called a **life table** [see Section 10.1 in singerwillett_AppliedLongitudinalData_2003], tracks the event histories (the \"lives\") of the sample from the beginning of time (when no one has experienced the target event) to the end of data collection (when everyone has either experienced the target event or been censored). For now we are only interested in first four variables, which we can use to explore event occurrence over time:\n\n- `time`: the time point, $t$\n- `n.risk`: the number of males at risk at time $t$\n- `n.event`: the number of events that occurred at time $t$\n- `n.censor`:\tthe number of males who exited the risk set, without an event, at time $t$\n\nThere are two ways to visualize this data: First, we can explore how the risk set changes over time, and second, we can explore what events occurred at each time $t$. Additionally, these visualizations can either be stepped or not; we'll visualize both versions for completeness sake.\n\n#### Event history\n\nWe'll start by exploring how the risk set changes over time. This requires further transformation of the data to (1) get the appropriate counts at each time point, (2) pivot to a tidier format, and (3) create steps for each time point.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_risk_set <- veterans_km_fit_tidy |>\n  # (1) Get the appropriate counts at each time point.\n  mutate(\n    alive = n.risk - n.event - n.censor,\n    dead = cumsum(n.event),\n    censored = cumsum(n.censor)\n  ) |>\n  select(time, alive, dead, censored) |>\n  # (2) Pivot to a tidier format.\n  pivot_longer(-time, names_to = \"status\", values_to = \"n\") |>\n  mutate(status = factor(status, levels = c(\"censored\", \"dead\", \"alive\")))\n\nglimpse(veterans_risk_set)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 306\n#> Columns: 3\n#> $ time   <dbl> 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 7, 7, 7, 8, 8, 8, …\n#> $ status <fct> alive, dead, censored, alive, dead, censored, alive, dead, cens…\n#> $ n      <dbl> 137, 0, 0, 135, 2, 0, 134, 3, 0, 133, 4, 0, 132, 5, 0, 129, 8, …\n```\n:::\n\n```{.r .cell-code}\n# (3) Create steps for each time point.\nveterans_risk_set_stepped <- veterans_km_fit_tidy |>\n  mutate(\n    alive = n.risk - n.event - n.censor,\n    died = alive + cumsum(n.event),\n    censored = died + cumsum(n.censor)\n  ) |>\n  select(time, alive, died, censored) |>\n  pivot_longer(-time, names_to = \"status\", values_to = \"n\") |>\n  mutate(status = factor(status, levels = c(\"censored\", \"died\", \"alive\")))\n\n# Based on: https://stackoverflow.com/a/41962072/16844576\nveterans_risk_set_stepped <- bind_rows(\n  raw = veterans_risk_set_stepped,\n  step = mutate(veterans_risk_set_stepped, n = lag(n, nlevels(status))),\n  .id = \"source\"\n) |>\n  arrange(time, desc(source))\n\nglimpse(veterans_risk_set_stepped)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 612\n#> Columns: 4\n#> $ source <chr> \"step\", \"step\", \"step\", \"raw\", \"raw\", \"raw\", \"step\", \"step\", \"s…\n#> $ time   <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, …\n#> $ status <fct> alive, died, censored, alive, died, censored, alive, died, cens…\n#> $ n      <dbl> NA, NA, NA, 137, 137, 137, 137, 137, 137, 135, 137, 137, 135, 1…\n```\n:::\n:::\n\n\n@fig-veteran-risk-set depicts how the risk set of the `veteran` data changed over time. This is a standard event history for survival data...\n\nThe advantage of the stepped version is that it makes it easier to see when events occurred. It also matches the survival curve plots we'll create later, which are all visualized with step functions. The disadvantage is that it involves more code. If this was going to be reported to others I would use the stepped version, but for personal exploration I would use the not stepped version.\n\n\n::: {#fig-veteran-risk-set .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\nggplot(veterans_risk_set, aes(x = time, y = n, fill = status)) +\n  geom_area() +\n  scale_fill_manual(values = c(\"#1b6ca8\", \"#cd201f\", \"#3aaf85\"))\n\nggplot(veterans_risk_set_stepped, aes(x = time, y = n, fill = status)) +\n  geom_ribbon(aes(ymin = 0, ymax = n)) +\n  scale_fill_manual(values = c(\"#1b6ca8\", \"#cd201f\", \"#3aaf85\"))\n```\n\n::: {.cell-output-display}\n![Not stepped](index_files/figure-html/fig-veteran-risk-set-1.png){#fig-veteran-risk-set-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Stepped](index_files/figure-html/fig-veteran-risk-set-2.png){#fig-veteran-risk-set-2 width=672}\n:::\n\nEvent history of the `veteran` data, depicting how the risk set changes\nover time.\n\n:::\n\n\nAs a compliment to @fig-veteran-risk-set, we can also explore what events occurred at each time $t$. @fig-veteran-events depicts the event history of the `veteran` data over time---this is essentially a more information rich version of [risk tables](http://www.danieldsjoberg.com/ggsurvfit/reference/add_risktable.html) that are sometimes appended to survival curve plots.\n\nThe code for this is nearly identical to the code for the previous plots---the main difference is how we calculate the counts at each time point---so I've folded it here.\n\n\n::: {#fig-veteran-events .cell layout-ncol=\"2\"}\n\n```{.r .cell-code  code-fold=\"true\"}\nveterans_events <- veterans_km_fit_tidy |>\n  # (1) Get the appropriate counts at each time point. Now we use the raw counts\n  # rather than cumulative sums.\n  mutate(\n    none = n.risk - n.event - n.censor,\n    died = n.event,\n    censored = n.censor\n  ) |>\n  select(time, none, died, censored) |>\n  # (2) Pivot to a tidier format.\n  pivot_longer(-time, names_to = \"event\", values_to = \"n\") |>\n  mutate(event = factor(event, levels = c(\"censored\", \"died\", \"none\")))\n\n# (3) Create steps for each time point.\nveterans_events_stepped <- veterans_km_fit_tidy |>\n  mutate(\n    none = n.risk - n.event - n.censor,\n    died = none + n.event,\n    censored = died + n.censor\n  ) |>\n  select(time, none, died, censored) |>\n  pivot_longer(-time, names_to = \"event\", values_to = \"n\") |>\n  mutate(event = factor(event, levels = c(\"censored\", \"died\", \"none\")))\n\nveterans_events_stepped <- bind_rows(\n  raw = veterans_events_stepped,\n  step = mutate(veterans_events_stepped, n = lag(n, nlevels(event))),\n  .id = \"source\"\n) |>\n  arrange(time, desc(source))\n\nggplot(veterans_events, aes(x = time, y = n, fill = event)) +\n  geom_area() +\n  scale_fill_manual(values = c(\"#1b6ca8\", \"#cd201f\", \"#3aaf85\"))\n\nggplot(veterans_events_stepped, aes(x = time, y = n, fill = event)) +\n  geom_ribbon(aes(ymin = 0, ymax = n)) +\n  scale_fill_manual(values = c(\"#1b6ca8\", \"#cd201f\", \"#3aaf85\"))\n```\n\n::: {.cell-output-display}\n![Not stepped](index_files/figure-html/fig-veteran-events-1.png){#fig-veteran-events-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Stepped](index_files/figure-html/fig-veteran-events-2.png){#fig-veteran-events-2 width=672}\n:::\n\nEvent history of the `veteran` data, depicting what events occurred at each\ntime $t$.\n\n:::\n\n\n#### Survival curves\n\nNow we're ready to explore the Kaplan-Meier estimates of the survival probability over time. First, let's look at the life table data again:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(veterans_km_fit_tidy)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 102\n#> Columns: 8\n#> $ time      <dbl> 0, 1, 2, 3, 4, 7, 8, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21,…\n#> $ n.risk    <dbl> 137, 137, 135, 134, 133, 132, 129, 125, 123, 122, 120, 118, …\n#> $ n.event   <dbl> 0, 2, 1, 1, 1, 3, 4, 2, 1, 2, 2, 2, 1, 3, 2, 2, 2, 1, 2, 3, …\n#> $ n.censor  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n#> $ estimate  <dbl> 1.0000000, 0.9854015, 0.9781022, 0.9708029, 0.9635036, 0.941…\n#> $ std.error <dbl> 0.00000000, 0.01039891, 0.01278345, 0.01481644, 0.01662791, …\n#> $ conf.high <dbl> 1.0000000, 1.0000000, 1.0000000, 0.9994081, 0.9954216, 0.981…\n#> $ conf.low  <dbl> 1.0000000, 0.9655208, 0.9539002, 0.9430165, 0.9326091, 0.903…\n```\n:::\n:::\n\n\nThe last four variables, which we skipped over earlier, are the Kaplan-Meier estimates of the survival probability over time:\n\n- `estimate`: Estimate of the survival function, the probability of surviving up to time $t$\n- `std.error`: The standard error of the regression term\n- `conf.high`: Upper bound on the pointwise confidence interval for the estimate\n- `conf.low`: Lower bound on the pointwise confidence interval for the estimate\n\nThese estimates and their intervals can be plotted as a **survival curve**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  veterans_km_fit_tidy,\n  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high)\n) +\n  geom_lineribbon(step = \"hv\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nTo better visualize uncertainty about our estimates, we can plot multiple intervals of different widths. To do this we first create a small helper function, `dist_tidy()`, to get multiple intervals from a survival model with additional `.width` and `level` columns for compatibility with `ggdist::geom_lineribbon()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist_tidy <- function(x, conf.type = \"log-log\", conf.int = 0.95, ...) {\n  purrr::map_df(\n    purrr::set_names(conf.int),\n    function(.x) broom::tidy(update(x, conf.type = conf.type, conf.int = .x)),\n    .id = \".width\"\n  ) |>\n  dplyr::mutate(\n    # ggdist automatically pulls from the .width column of summarized data to\n    # plot multiple intervals. The width column should be numeric for this to\n    # work correctly.\n    .width = as.numeric(.width),\n    # ggdist turns .width into level internally with its stat_ geoms, but for\n    # geom_ geoms we need to do this in the summary data. This is mainly for\n    # ease of use with the fill_ramp aesthetic.\n    level  = factor(.width, levels = sort(conf.int, decreasing = TRUE))\n  ) |>\n  dplyr::relocate(.width, level, .after = dplyr::everything()) |>\n  # The last time always has NAs for the CIs and it's important to remove this;\n  # otherwise the fills in ggdist::geom_lineribbon() will plot incorrectly.\n  na.omit()\n}\n```\n:::\n\n\nThen we can plot the survival curve with multiple intervals (here 66% and 95%) using the data tidied with `dist_tidy()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_km_fit_dist <- dist_tidy(veterans_km_fit, conf.int = c(0.66, 0.95))\n\np_veterans_km <- ggplot(\n  veterans_km_fit_dist,\n  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high)\n) +\n  geom_lineribbon(step = \"hv\") +\n  scale_fill_brewer()\n\np_veterans_km\n```\n\n::: {.cell-output-display}\n![Kaplan-Meier survival curve with 66% and 95% intervals](index_files/figure-html/fig-veteran-km-curve-1.png){#fig-veteran-km-curve width=672}\n:::\n:::\n\n\nIt may also be desirable to add additional info to the survival curve plot, like when censoring occurred. A non-invasive way to do this is to add a rug of censored times to the x-axis. A more common approach is to add points directly on the survival curve where censored events occurred. These points are often plotted as black \"+\" signs, which can be hard to see; here I plot them as red points instead.\n\n\n::: {#fig-veteran-censored .cell layout-ncol=\"2\"}\n\n```{.r .cell-code}\n# To add censoring information to the plot we need a data frame containing only\n# the censored observations.\nveterans_km_fit_tidy_censored <-\n  filter(veterans_km_fit_tidy, n.censor != 0)\n\n# With a rug\np_veterans_km +\n  geom_rug(aes(y = NULL), data = veterans_km_fit_tidy_censored)\n\n# With points\np_veterans_km +\n  geom_point(\n    data = veterans_km_fit_tidy_censored,\n    colour = \"red\"\n  )\n```\n\n::: {.cell-output-display}\n![Rug](index_files/figure-html/fig-veteran-censored-1.png){#fig-veteran-censored-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Points](index_files/figure-html/fig-veteran-censored-2.png){#fig-veteran-censored-2 width=672}\n:::\n\nCensoring times in the `veteran` data.\n\n:::\n\n\nAlong with the life table data, which we use to plot the survival curve, the `survfit` object stores the following summary statistics:\n\n- `records`: Number of observations\n- `n.max`: Maximum number of subjects at risk\n- `n.start`: Initial number of subjects at risk\n- `events`: Number of events\n- `rmean`: Restricted mean survival\n- `rmean.std.error`: Restricted mean standard error\n- `median`: Median survival\n- `conf.low`: Lower end of confidence interval on median\n- `conf.high`: Upper end of confidence interval on median\n- `nobs`: Number of observations used\n\nThey can be retrieved with `broom::glance()`:\n\n::: {.column-margin}\nThe method used to resolve the restricted mean survival estimate when the last observation is not a death can be set with the optional `rmean` argument in `broom::glance()`. For details, see `?survival::print.survfit` and `?broom::glance.survfit`.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_km_fit_summary <- glance(veterans_km_fit)\n\nglimpse(veterans_km_fit_summary)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> Rows: 1\n#> Columns: 10\n#> $ records         <dbl> 137\n#> $ n.max           <dbl> 137\n#> $ n.start         <dbl> 137\n#> $ events          <dbl> 128\n#> $ rmean           <dbl> 132.7768\n#> $ rmean.std.error <dbl> 15.30789\n#> $ median          <dbl> 80\n#> $ conf.low        <dbl> 52\n#> $ conf.high       <dbl> 105\n#> $ nobs            <int> 137\n```\n:::\n:::\n\n\nThese summary statistics can be included in the survival curve plot as well. For example, the **median survival time**:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_veterans_km +\n  geom_segment(\n    aes(x = -Inf, xend = conf.high, y = 0.5, yend = 0.5),\n    data = veterans_km_fit_summary,\n    linetype = 2,\n    inherit.aes = FALSE\n  ) +\n  geom_rect(\n    aes(xmin = conf.low, xmax = conf.high, ymin = 0, ymax = 0.5),\n    data = veterans_km_fit_summary,\n    alpha = 0.5,\n    inherit.aes = FALSE\n  ) +\n  geom_segment(\n    aes(x = median, xend = median, y = 0, yend = 0.5),\n    data = veterans_km_fit_summary,\n    inherit.aes = FALSE\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n#### Cumulative risk (incidence) curves\n\nThe **cumulative risk** (aka cumulative incidence) at a time point is simply one minus the survival probability:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_veterans_risk <- ggplot(\n  veterans_km_fit_dist,\n  aes(x = time, y = 1 - estimate, ymin = 1 - conf.low, ymax = 1 - conf.high)\n) +\n  geom_lineribbon(step = \"hv\") +\n  scale_fill_brewer()\n\np_veterans_risk\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n#### Cumulative hazard curves\n\nThe cumulative hazard function can be estimated in two ways:\n\n- the negative log survivor function method\n- the Nelson-Aalen method\n\nIn general both methods give similar estimates, particularly at early event times when the risk set is large. However, they tend to diverge as the size of the risk set decreases.\n\nThe negative log survivor function method involves transforming the Kaplan-Meier estimates of survival probability over time by taking their negative log. The resulting estimates of the cumulative hazard function are called **negative log survivor function estimates**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_veterans_cumhaz <- ggplot(\n  veterans_km_fit_dist,\n  aes(x = time, y = -log(estimate), ymin = -log(conf.low), ymax = -log(conf.high))\n) +\n  geom_lineribbon(step = \"vh\") +\n  scale_fill_brewer()\n\np_veterans_cumhaz\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nEstimates of the cumulative hazard function and their standard error using the Nelson-Aalen method are included in the `survfit` object as `object$cumhaz` and `object$std.chaz`, respectively. No confidence intervals are returned, however.\n\n#### Kernel smoothed hazard curves\n\nThe **muhaz** package provides a method for gettinng kernel smoothed estimates of the hazard function. The function API isn't great, so we wrap it in a small helper function to make things cleaner. No intervals are provided for these estimates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(muhaz)\n\nhaz_tidy <- function(x, ...) {\n  x <- broom::tidy(survival::survfit0(x))\n  haz <- muhaz::muhaz(\n    times = x$time,\n    delta = x$n.censor,\n    min.time = min(x$time),\n    max.time = max(x$time),\n    bw.method = \"global\",\n    b.cor = \"none\",\n    ...\n  )\n  broom::tidy(haz)\n}\n\nggplot(haz_tidy(veterans_km_fit), aes(x = time, y = estimate)) +\n  geom_line()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n### Statistical modelling\n\n### Predictive methods\n\n## Multiple groups\n\nTODO: Decide whether to have a single arm trial section AND a multi-group RCT section (mainly because there are some code differences between the two)\n\nMultiple survival curves on one plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_fit <- survfit(Surv(time, status) ~ trt, data = veteran)\nveterans_fit_tidy <- dist_tidy(veterans_fit, conf.int = c(0.66, 0.95))\n\np <- ggplot(\n  veterans_fit_tidy,\n  aes(x = time, y = estimate, ymin = conf.low, ymax = conf.high, fill = strata)\n) +\n  geom_lineribbon(aes(fill_ramp = level), step = \"hv\")\n\np\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nThis specific example might be better server with a faceted plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\np + facet_wrap(vars(strata), ncol = 1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n`glance()` only supports models that can be summarized in a single row. We can refit the survival model to subsets as a workaround to get `glance()` to work for multi-strata survival models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_fit_glance <- map_df(\n  c(\"trt=1\" = 1, \"trt=2\" = 2),\n  function(.x) glance(update(veterans_fit, subset = (trt == .x))),\n  .id = \"strata\"\n)\n\nveterans_fit_glance\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"strata\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"records\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n.max\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n.start\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"events\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmean\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmean.std.error\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"median\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"trt=1\",\"2\":\"69\",\"3\":\"69\",\"4\":\"69\",\"5\":\"64\",\"6\":\"123.9282\",\"7\":\"14.84352\",\"8\":\"103.0\",\"9\":\"59\",\"10\":\"132\",\"11\":\"69\"},{\"1\":\"trt=2\",\"2\":\"68\",\"3\":\"68\",\"4\":\"68\",\"5\":\"64\",\"6\":\"142.0613\",\"7\":\"26.81071\",\"8\":\"52.5\",\"9\":\"44\",\"10\":\"95\",\"11\":\"68\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nAlternatively, use `summary()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(veterans_fit)[[\"table\"]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>       records n.max n.start events    rmean se(rmean) median 0.95LCL 0.95UCL\n#> trt=1      69    69      69     64 123.9282  14.84352  103.0      59     132\n#> trt=2      68    68      68     64 142.0613  26.81071   52.5      44      95\n```\n:::\n:::\n\n\n<!--\n#### Length of follow-up\n\nIt probably isn't necessary to quantify length of follow-up, see rufibachetal_QuantificationFollowupTime_2022\n\n> One measure of the quality of a clinical trial is the duration of follow-up, as measured by the median follow-up time. This is a measure that captures how long, on average, patients have been followed.\n\n> Time-to-event studies must have sufficiently long follow-up durations to capture enough events to reveal meaningful patterns in the data. https://en.wikipedia.org/wiki/Median_follow-up\n\n> Time to event studies must have sufficient follow-up to capture enough events and thereby ensure there is sufficient power to perform appropriate statistical tests. The proposed length of followup for a prospective study will be based primarily on the severity of the disease or prognosis of the participants.\n\nThe median follow-up time can be obtained using the **reverse Kaplan-Meier method**, wherein the censoring status indicators are reversed (0 = no, 1 = yes) before estimating the survival function. Here the target event is now interpreted as censored in the sense that a person's observation time could have been longer had they not experienced the target event, and the survival estimates are now interpreted as the percent of the sample that have either had the event or remained under observation at time $t$.\n\nThe median follow-up time can be obtained using the **reverse Kaplan-Meier method**, wherein the censoring status indicators are reversed (0 = no, 1 = yes) before estimating the survival function. Here the target event is now interpreted as censored in the sense that a person's observation time could have been longer had they not experienced the target event, and the survival estimates are now interpreted as the percent of the sample being followed at time $t$.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nveterans_fu_fit <- survfit(Surv(time, 1 - status) ~ 1, data = veteran)\n```\n:::\n\n\nThe median follow-up time is then simply the median survival time of this model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(veterans_fu_fit)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"records\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n.max\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n.start\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"events\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmean\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rmean.std.error\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"median\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.low\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"conf.high\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"nobs\"],\"name\":[10],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"137\",\"2\":\"137\",\"3\":\"137\",\"4\":\"9\",\"5\":\"838.8409\",\"6\":\"52.42938\",\"7\":\"NA\",\"8\":\"NA\",\"9\":\"NA\",\"10\":\"137\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nHowever, as is the case here, this has the drawback that the median follow-up time will be undefined (`NA`) if 50% of the sample had not been followed at the time of study end.\n\nthe survival curve never crosses the 0.5 line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tidy(survfit0(veterans_fu_fit)), aes(x = time, y = estimate)) +\n  geom_step() +\n  geom_hline(yintercept = 0.5, linetype = 2) +\n  coord_cartesian(ylim = c(0, 1))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n\nA simpler approach is to find the median of all survival times, whether censored or not; however in studies with many early events, but a long observation period, this can give the appearance of a short median follow-up time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(veteran$time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>   0%  25%  50%  75% 100% \n#>    1   25   80  144  999\n```\n:::\n:::\n\n\nIn this data set the median is defined:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(lung$time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#>      0%     25%     50%     75%    100% \n#>    5.00  166.75  255.50  396.50 1022.00\n```\n:::\n\n```{.r .cell-code}\nsurvfit(Surv(time, abs(status - 2)) ~ 1, data = lung) |>\n  quantile()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#> $quantile\n#>  25  50  75 \n#> 301 588 965 \n#> \n#> $lower\n#>  25  50  75 \n#> 272 511 821 \n#> \n#> $upper\n#>   25   50   75 \n#>  404 1010   NA\n```\n:::\n:::\n\n-->\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}